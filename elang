#!/usr/bin/env python

import unittest
import click
import sys

from core.lexer import Lexer
from core.parser import Parser


lexer = Lexer()
parser = Parser()


has_file_option = click.option(
    '--file',
    help='file used as input',
    type=click.File('r'),
    default=sys.stdin)


has_format_option = click.option(
    '--format',
    help='format of stdout',
    type=click.Choice(['lines', 'json'], case_sensitive=False),
    default='lines')


@click.group()
def cli():
    pass


@cli.command()
@has_file_option
@has_format_option
def lex(file, format):
    """Perform Lexical Analysis"""
    if format == 'lines':
        tokens = lexer.from_program_file(file)
        for line in Lexer.as_lines(tokens):
            print(line)
    elif format == 'json':
        raise click.ClickException('format not implemented')
    else:
        raise click.ClickException('invalid format')


@cli.command()
@has_file_option
@has_format_option
def parse(file, format):
    """Perform Syntactic Analysis"""
    tokens = lexer.from_token_file(file)
    ast = parser(tokens)
    if format == 'lines':
        for line in ast.as_lines():
            print(line)
    elif format == 'json':
        print(ast.as_json())
    else:
        raise click.ClickException('invalid output format')


@cli.command()
@click.argument('test_name', required=False)
def test(test_name):
    """
    Run unit tests.

    \b
    Example - run all unit tests:
    elang test

    \b
    Example - run specific test:
    elang test tests.test_lexer_tokens.TestTokens.test_keywords

    \b
    Example - run specific test case/class:
    elang test tests.test_lexer_tokens.TestTokens

    \b
    Example - run specific test module/file:
    elang test tests.test_lexer_tokens
    """
    if test_name is None:
        tests = unittest.TestLoader().discover('tests')
    else:
        tests = unittest.TestLoader().loadTestsFromName(test_name)
    unittest.TextTestRunner(verbosity=2).run(tests)


if __name__ == '__main__':
    cli()
